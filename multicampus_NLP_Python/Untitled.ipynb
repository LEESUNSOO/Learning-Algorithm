{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn 라이브러리 임포트\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas 라이브러리 임포트\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df2 = pd.DataFrame(wine.target)#, columns=wine.feature_names)\n",
    "\n",
    "#excel_writer = pd.ExcelWriter('excel_output.xlsx', engine = 'xlsxwriter')\n",
    "excel_writer2 = pd.ExcelWriter('excel_output_target.xlsx', engine = 'xlsxwriter')\n",
    "#df1.to_excel(excel_writer)\n",
    "df2.to_excel(excel_writer2)\n",
    "\n",
    "#excel_writer.save()\n",
    "excel_writer2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data[0:130] # 130으로 제한한 이유는 라벨값이 0,1 로만 존재하기 위해서이다\n",
    "wine_target = wine.target[0:130] # 아마 추측하기로는 crossentropyloss가 라벨값으로 원핫벡터값을 갖기 때문 같은데 모르겠다 ^^ !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.237e+01, 1.630e+00, 2.300e+00, ..., 8.900e-01, 2.780e+00,\n",
       "        3.420e+02],\n",
       "       [1.164e+01, 2.060e+00, 2.460e+00, ..., 1.000e+00, 2.750e+00,\n",
       "        6.800e+02],\n",
       "       [1.229e+01, 1.610e+00, 2.210e+00, ..., 9.060e-01, 1.820e+00,\n",
       "        8.700e+02],\n",
       "       ...,\n",
       "       [1.305e+01, 1.650e+00, 2.550e+00, ..., 1.120e+00, 2.510e+00,\n",
       "        1.105e+03],\n",
       "       [1.390e+01, 1.680e+00, 2.120e+00, ..., 9.100e-01, 3.330e+00,\n",
       "        9.850e+02],\n",
       "       [1.145e+01, 2.400e+00, 2.420e+00, ..., 8.000e-01, 3.390e+00,\n",
       "        6.250e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(wine_data, wine_target, test_size = 0.2)\n",
    "# 사이킷런에서 얻은 데이터셋을 train_test_split함수르 통해 트레인/테스트 용 설명/목적 변수를 8:2 비율로 나눈다\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104, 13])\n",
      "torch.Size([104])\n",
      "tensor([[  12.3700,    1.6300,    2.3000,  ...,    0.8900,    2.7800,\n",
      "          342.0000],\n",
      "        [  11.6400,    2.0600,    2.4600,  ...,    1.0000,    2.7500,\n",
      "          680.0000],\n",
      "        [  12.2900,    1.6100,    2.2100,  ...,    0.9060,    1.8200,\n",
      "          870.0000],\n",
      "        ...,\n",
      "        [  13.0500,    1.6500,    2.5500,  ...,    1.1200,    2.5100,\n",
      "         1105.0000],\n",
      "        [  13.9000,    1.6800,    2.1200,  ...,    0.9100,    3.3300,\n",
      "          985.0000],\n",
      "        [  11.4500,    2.4000,    2.4200,  ...,    0.8000,    3.3900,\n",
      "          625.0000]])\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.from_numpy(train_X).float() # 행렬화 실수니까~\n",
    "train_Y = torch.from_numpy(train_Y).long() # 행렬화 정수니까~\n",
    "\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(train_X)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 12.3700,   1.6300,   2.3000,  24.5000,  88.0000,   2.2200,   2.4500,\n",
      "          0.4000,   1.9000,   2.1200,   0.8900,   2.7800, 342.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.6400,   2.0600,   2.4600,  21.6000,  84.0000,   1.9500,   1.6900,\n",
      "          0.4800,   1.3500,   2.8000,   1.0000,   2.7500, 680.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.2900,   1.6100,   2.2100,  20.4000, 103.0000,   1.1000,   1.0200,\n",
      "          0.3700,   1.4600,   3.0500,   0.9060,   1.8200, 870.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.0000,   0.9200,   2.0000,  19.0000,  86.0000,   2.4200,   2.2600,\n",
      "          0.3000,   1.4300,   2.5000,   1.3800,   3.1200, 278.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.9400,    1.7300,    2.2700,   17.4000,  108.0000,    2.8800,\n",
      "           3.5400,    0.3200,    2.0800,    8.9000,    1.1200,    3.1000,\n",
      "        1260.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.0700,    1.5000,    2.1000,   15.5000,   98.0000,    2.4000,\n",
      "           2.6400,    0.2800,    1.3700,    3.7000,    1.1800,    2.6900,\n",
      "        1020.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.0700,   2.1600,   2.1700,  21.0000,  85.0000,   2.6000,   2.6500,\n",
      "          0.3700,   1.3500,   2.7600,   0.8600,   3.2800, 378.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.5600,    1.7300,    2.4600,   20.5000,  116.0000,    2.9600,\n",
      "           2.7800,    0.2000,    2.4500,    6.2500,    0.9800,    3.0300,\n",
      "        1120.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.8200,    1.7500,    2.4200,   14.0000,  111.0000,    3.8800,\n",
      "           3.7400,    0.3200,    1.8700,    7.0500,    1.0100,    3.2600,\n",
      "        1190.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.5100,   1.7300,   1.9800,  20.5000,  85.0000,   2.2000,   1.9200,\n",
      "          0.3200,   1.4800,   2.9400,   1.0400,   3.5700, 672.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.0300,   0.9000,   1.7100,  16.0000,  86.0000,   1.9500,   2.0300,\n",
      "          0.2400,   1.4600,   4.6000,   1.1900,   2.4800, 392.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 14.2200,   3.9900,   2.5100,  13.2000, 128.0000,   3.0000,   3.0400,\n",
      "          0.2000,   2.0800,   5.1000,   0.8900,   3.5300, 760.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.7700,    1.9000,    2.6800,   17.1000,  115.0000,    3.0000,\n",
      "           2.7900,    0.3900,    1.6800,    6.3000,    1.1300,    2.9300,\n",
      "        1375.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.6500,   1.6700,   2.6200,  26.0000,  88.0000,   1.9200,   1.6100,\n",
      "          0.4000,   1.3400,   2.6000,   1.3600,   3.2100, 562.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.1900,    1.5900,    2.4800,   16.5000,  108.0000,    3.3000,\n",
      "           3.9300,    0.3200,    1.8600,    8.7000,    1.2300,    2.8200,\n",
      "        1680.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.2500,   1.7300,   2.1200,  19.0000,  80.0000,   1.6500,   2.0300,\n",
      "          0.3700,   1.6300,   3.4000,   1.0000,   3.1700, 510.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.4600,   3.7400,   1.8200,  19.5000, 107.0000,   3.1800,   2.5800,\n",
      "          0.2400,   3.5800,   2.9000,   0.7500,   2.8100, 562.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.5600,   2.0500,   3.2300,  28.5000, 119.0000,   3.1800,   5.0800,\n",
      "          0.4700,   1.8700,   6.0000,   0.9300,   3.6900, 465.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.2000,    1.7800,    2.1400,   11.2000,  100.0000,    2.6500,\n",
      "           2.7600,    0.2600,    1.2800,    4.3800,    1.0500,    3.4000,\n",
      "        1050.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.7500,    1.7300,    2.3900,   11.4000,   91.0000,    3.1000,\n",
      "           3.6900,    0.4300,    2.8100,    5.4000,    1.2500,    2.7300,\n",
      "        1150.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.0600,    2.1500,    2.6100,   17.6000,  121.0000,    2.6000,\n",
      "           2.5100,    0.3100,    1.2500,    5.0500,    1.0600,    3.5800,\n",
      "        1295.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.3300,   1.1000,   2.2800,  16.0000, 101.0000,   2.0500,   1.0900,\n",
      "          0.6300,   0.4100,   3.2700,   1.2500,   1.6700, 680.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.3300,   0.9900,   1.9500,  14.8000, 136.0000,   1.9000,   1.8500,\n",
      "          0.3500,   2.7600,   3.4000,   1.0600,   2.3100, 750.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.0800,   1.3300,   2.3000,  23.6000,  70.0000,   2.2000,   1.5900,\n",
      "          0.4200,   1.3800,   1.7400,   1.0700,   3.2100, 625.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.2400,   3.9800,   2.2900,  17.5000, 103.0000,   2.6400,   2.6300,\n",
      "          0.3200,   1.6600,   4.3600,   0.8200,   3.0000, 680.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.7900,   2.1300,   2.7800,  28.5000,  92.0000,   2.1300,   2.2400,\n",
      "          0.5800,   1.7600,   3.0000,   0.9700,   2.4400, 466.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.3900,    1.8700,    2.4500,   14.6000,   96.0000,    2.5000,\n",
      "           2.5200,    0.3000,    1.9800,    5.2500,    1.0200,    3.5800,\n",
      "        1290.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.9300,   3.8000,   2.6500,  18.6000, 102.0000,   2.4100,   2.4100,\n",
      "          0.2500,   1.9800,   4.5000,   1.0300,   3.5200, 770.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.3800,    3.5900,    2.2800,   16.0000,  102.0000,    3.2500,\n",
      "           3.1700,    0.2700,    2.1900,    4.9000,    1.0400,    3.4400,\n",
      "        1065.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.3400,   2.4500,   2.4600,  21.0000,  98.0000,   2.5600,   2.1100,\n",
      "          0.3400,   1.3100,   2.8000,   0.8000,   3.3800, 438.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.9900,   1.6700,   2.6000,  30.0000, 139.0000,   3.3000,   2.8900,\n",
      "          0.2100,   1.9600,   3.3500,   1.3100,   3.5000, 985.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.2800,   1.6400,   2.8400,  15.5000, 110.0000,   2.6000,   2.6800,\n",
      "          0.3400,   1.3600,   4.6000,   1.0900,   2.7800, 880.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.0800,   2.0800,   1.7000,  17.5000,  97.0000,   2.2300,   2.1700,\n",
      "          0.2600,   1.4000,   3.3000,   1.2700,   2.9600, 710.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.0300,   1.5100,   2.2000,  21.5000,  85.0000,   2.4600,   2.1700,\n",
      "          0.5200,   2.0100,   1.9000,   1.7100,   2.8700, 407.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.2900,   3.1700,   2.2100,  18.0000,  88.0000,   2.8500,   2.9900,\n",
      "          0.4500,   2.8100,   2.3000,   1.4200,   2.8300, 406.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.8600,    1.3500,    2.2700,   16.0000,   98.0000,    2.9800,\n",
      "           3.1500,    0.2200,    1.8500,    7.2200,    1.0100,    3.5500,\n",
      "        1045.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.6400,   1.3600,   2.0200,  16.8000, 100.0000,   2.0200,   1.4100,\n",
      "          0.5300,   0.6200,   5.7500,   0.9800,   1.5900, 450.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.6700,   0.9800,   2.2400,  18.0000,  99.0000,   2.2000,   1.9400,\n",
      "          0.3000,   1.4600,   2.6200,   1.2300,   3.1600, 450.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.3700,   1.1700,   1.9200,  19.6000,  78.0000,   2.1100,   2.0000,\n",
      "          0.2700,   1.0400,   4.6800,   1.1200,   3.4800, 510.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.3000,    1.9200,    2.7200,   20.0000,  120.0000,    2.8000,\n",
      "           3.1400,    0.3300,    1.9700,    6.2000,    1.0700,    2.6500,\n",
      "        1280.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.0000,   3.4300,   2.0000,  19.0000,  87.0000,   2.0000,   1.6400,\n",
      "          0.3700,   1.8700,   1.2800,   0.9300,   3.0500, 564.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.8300,    1.5700,    2.6200,   20.0000,  115.0000,    2.9500,\n",
      "           3.4000,    0.4000,    1.7200,    6.6000,    1.1300,    2.5700,\n",
      "        1130.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.8200,   1.7200,   1.8800,  19.5000,  86.0000,   2.5000,   1.6400,\n",
      "          0.3700,   1.4200,   2.0600,   0.9400,   2.4400, 415.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.8600,   1.5100,   2.6700,  25.0000,  86.0000,   2.9500,   2.8600,\n",
      "          0.2100,   1.8700,   3.3800,   1.3600,   3.1600, 410.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.3800,    1.8700,    2.3800,   12.0000,  102.0000,    3.3000,\n",
      "           3.6400,    0.2900,    2.9600,    7.5000,    1.2000,    3.0000,\n",
      "        1547.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.7200,    1.4300,    2.5000,   16.7000,  108.0000,    3.4000,\n",
      "           3.6700,    0.1900,    2.0400,    6.8000,    0.8900,    2.8700,\n",
      "        1285.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.8100,   2.1200,   2.7400,  21.5000, 134.0000,   1.6000,   0.9900,\n",
      "          0.1400,   1.5600,   2.5000,   0.9500,   2.2600, 625.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.4100,    3.8400,    2.1200,   18.8000,   90.0000,    2.4500,\n",
      "           2.6800,    0.2700,    1.4800,    4.2800,    0.9100,    3.0000,\n",
      "        1035.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.2900,   2.8300,   2.2200,  18.0000,  88.0000,   2.4500,   2.2500,\n",
      "          0.2500,   1.9900,   2.1500,   1.1500,   3.3000, 290.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.0500,    1.7300,    2.0400,   12.4000,   92.0000,    2.7200,\n",
      "           3.2700,    0.1700,    2.9100,    7.2000,    1.1200,    2.9100,\n",
      "        1150.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.2000,    1.7600,    2.4500,   15.2000,  112.0000,    3.2700,\n",
      "           3.3900,    0.3400,    1.9700,    6.7500,    1.0500,    2.8500,\n",
      "        1450.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.4700,   1.5200,   2.2000,  19.0000, 162.0000,   2.5000,   2.2700,\n",
      "          0.3200,   3.2800,   2.6000,   1.1600,   2.6300, 937.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.8400,   2.8900,   2.2300,  18.0000, 112.0000,   1.7200,   1.3200,\n",
      "          0.4300,   0.9500,   2.6500,   0.9600,   2.5200, 500.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.3400,   0.9400,   2.3600,  17.0000, 110.0000,   2.5300,   1.3000,\n",
      "          0.5500,   0.4200,   3.1700,   1.0200,   1.9300, 750.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.3700,   1.2100,   2.5600,  18.1000,  98.0000,   2.4200,   2.6500,\n",
      "          0.3700,   2.0800,   4.6000,   1.1900,   2.3000, 678.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.8700,   1.9000,   2.8000,  19.4000, 107.0000,   2.9500,   2.9700,\n",
      "          0.3700,   1.7600,   4.5000,   1.2500,   3.4000, 915.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.7100,    1.8600,    2.3600,   16.6000,  101.0000,    2.6100,\n",
      "           2.8800,    0.2700,    1.6900,    3.8000,    1.1100,    4.0000,\n",
      "        1035.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.7000,   3.8700,   2.4000,  23.0000, 101.0000,   2.8300,   2.5500,\n",
      "          0.4300,   1.9500,   2.5700,   1.1900,   3.1300, 463.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.2100,   1.1900,   1.7500,  16.8000, 151.0000,   1.8500,   1.2800,\n",
      "          0.1400,   2.5000,   2.8500,   1.2800,   3.0700, 718.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.5200,   2.4300,   2.1700,  21.0000,  88.0000,   2.5500,   2.2700,\n",
      "          0.2600,   1.2200,   2.0000,   0.9000,   2.7800, 325.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.6200,   1.9900,   2.2800,  18.0000,  98.0000,   3.0200,   2.2600,\n",
      "          0.1700,   1.3500,   3.2500,   1.1600,   2.9600, 345.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 14.2200,   1.7000,   2.3000,  16.3000, 118.0000,   3.2000,   3.0000,\n",
      "          0.2600,   2.0300,   6.3800,   0.9400,   3.3100, 970.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.8400,   0.8900,   2.5800,  18.0000,  94.0000,   2.2000,   2.2100,\n",
      "          0.2200,   2.3500,   3.0500,   0.7900,   3.0800, 520.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.2900,    1.9700,    2.6800,   16.8000,  102.0000,    3.0000,\n",
      "           3.2300,    0.3100,    1.6600,    6.0000,    1.0700,    2.8400,\n",
      "        1270.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.8800,    1.8900,    2.5900,   15.0000,  101.0000,    3.2500,\n",
      "           3.5600,    0.1700,    1.7000,    5.4300,    0.8800,    3.5600,\n",
      "        1095.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.2200,   1.2900,   1.9400,  19.0000,  92.0000,   2.3600,   2.0400,\n",
      "          0.3900,   2.0800,   2.7000,   0.8600,   3.0200, 312.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.0200,    1.6800,    2.2100,   16.0000,   96.0000,    2.6500,\n",
      "           2.3300,    0.2600,    1.9800,    4.7000,    1.0400,    3.5900,\n",
      "        1035.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.7200,   1.8100,   2.2000,  18.8000,  86.0000,   2.2000,   2.5300,\n",
      "          0.2600,   1.7700,   3.9000,   1.1600,   3.1400, 714.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  14.2300,    1.7100,    2.4300,   15.6000,  127.0000,    2.8000,\n",
      "           3.0600,    0.2800,    2.2900,    5.6400,    1.0400,    3.9200,\n",
      "        1065.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.5800,    1.6600,    2.3600,   19.1000,  106.0000,    2.8600,\n",
      "           3.1900,    0.2200,    1.9500,    6.9000,    1.0900,    2.8800,\n",
      "        1515.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.1000,    2.0200,    2.4000,   18.8000,  103.0000,    2.7500,\n",
      "           2.9200,    0.3200,    2.3800,    6.2000,    1.0700,    2.7500,\n",
      "        1060.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.6900,   1.5300,   2.2600,  20.7000,  80.0000,   1.3800,   1.4600,\n",
      "          0.5800,   1.6200,   3.0500,   0.9600,   2.0600, 495.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.4100,   0.7400,   2.5000,  21.0000,  88.0000,   2.4800,   2.0100,\n",
      "          0.4200,   1.4400,   3.0800,   1.1000,   2.3100, 434.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.3000,    1.7200,    2.1400,   17.0000,   94.0000,    2.4000,\n",
      "           2.1900,    0.2700,    1.3500,    3.9500,    1.0200,    2.7700,\n",
      "        1285.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.3700,    1.9500,    2.5000,   16.8000,  113.0000,    3.8500,\n",
      "           3.4900,    0.2400,    2.1800,    7.8000,    0.8600,    3.4500,\n",
      "        1480.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.4800,   1.8100,   2.4100,  20.5000, 100.0000,   2.7000,   2.9800,\n",
      "          0.2600,   1.8600,   5.1000,   1.0400,   3.4700, 920.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.2900,   1.4100,   1.9800,  16.0000,  85.0000,   2.5500,   2.5000,\n",
      "          0.2900,   1.7700,   2.9000,   1.2300,   2.7400, 428.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.7200,   1.7500,   2.2800,  22.5000,  84.0000,   1.3800,   1.7600,\n",
      "          0.4800,   1.6300,   3.3000,   0.8800,   2.4200, 488.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.0500,   5.8000,   2.1300,  21.5000,  86.0000,   2.6200,   2.6500,\n",
      "          0.3000,   2.0100,   2.6000,   0.7300,   3.1000, 380.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.6600,   1.8800,   1.9200,  16.0000,  97.0000,   1.6100,   1.5700,\n",
      "          0.3400,   1.1500,   3.8000,   1.2300,   2.1400, 428.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.7500,    1.7300,    2.4100,   16.0000,   89.0000,    2.6000,\n",
      "           2.7600,    0.2900,    1.8100,    5.6000,    1.1500,    2.9000,\n",
      "        1320.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.7600,   2.6800,   2.9200,  20.0000, 103.0000,   1.7500,   2.0300,\n",
      "          0.6000,   1.0500,   3.8000,   1.2300,   2.5000, 607.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.0400,   4.3000,   2.3800,  22.0000,  80.0000,   2.1000,   1.7500,\n",
      "          0.4200,   1.3500,   2.6000,   0.7900,   2.5700, 580.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.5100,    1.8000,    2.6500,   19.0000,  110.0000,    2.3500,\n",
      "           2.5300,    0.2900,    1.5400,    4.2000,    1.1000,    2.8700,\n",
      "        1095.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.6700,   1.2500,   1.9200,  18.0000,  94.0000,   2.1000,   1.7900,\n",
      "          0.3200,   0.7300,   3.8000,   1.2300,   2.4600, 630.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.7700,   3.4300,   1.9800,  16.0000,  80.0000,   1.6300,   1.2500,\n",
      "          0.4300,   0.8300,   3.4000,   0.7000,   2.1200, 372.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.0000,   1.5100,   2.4200,  22.0000,  86.0000,   1.4500,   1.2500,\n",
      "          0.5000,   1.6300,   3.6000,   1.0500,   2.6500, 450.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 11.9600,   1.0900,   2.3000,  21.0000, 101.0000,   3.3800,   2.1400,\n",
      "          0.1300,   1.6500,   3.2100,   0.9900,   3.1300, 886.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.4200,   1.6100,   2.1900,  22.5000, 108.0000,   2.0000,   2.0900,\n",
      "          0.3400,   1.6100,   2.0600,   1.0600,   2.9600, 345.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.0500,   2.0500,   3.2200,  25.0000, 124.0000,   2.6300,   2.6800,\n",
      "          0.4700,   1.9200,   3.5800,   1.1300,   3.2000, 830.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.7400,    1.6700,    2.2500,   16.4000,  118.0000,    2.6000,\n",
      "           2.9000,    0.2100,    1.6200,    5.8500,    0.9200,    3.2000,\n",
      "        1060.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  14.2100,    4.0400,    2.4400,   18.9000,  111.0000,    2.8500,\n",
      "           2.6500,    0.3000,    1.2500,    5.2400,    0.8700,    3.3300,\n",
      "        1080.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.6400,   3.1000,   2.5600,  15.2000, 116.0000,   2.7000,   3.0300,\n",
      "          0.1700,   1.6600,   5.1000,   0.9600,   3.3600, 845.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.3700,   1.0700,   2.1000,  18.5000,  88.0000,   3.5200,   3.7500,\n",
      "          0.2400,   1.9500,   4.5000,   1.0400,   2.7700, 660.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  12.8500,    1.6000,    2.5200,   17.8000,   95.0000,    2.4800,\n",
      "           2.3700,    0.2600,    1.4600,    3.9300,    1.0900,    3.6300,\n",
      "        1015.0000]), tensor(0))\n",
      "========\n",
      "(tensor([  13.7600,    1.5300,    2.7000,   19.5000,  132.0000,    2.9500,\n",
      "           2.7400,    0.5000,    1.3500,    5.4000,    1.2500,    3.0000,\n",
      "        1235.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.1100,   1.0100,   1.7000,  15.0000,  78.0000,   2.9800,   3.1800,\n",
      "          0.2600,   2.2800,   5.3000,   1.1200,   3.1800, 502.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 12.4200,   4.4300,   2.7300,  26.5000, 102.0000,   2.2000,   2.1300,\n",
      "          0.4300,   1.7100,   2.0800,   0.9200,   3.1200, 365.0000]), tensor(1))\n",
      "========\n",
      "(tensor([ 13.6800,   1.8300,   2.3600,  17.2000, 104.0000,   2.4200,   2.6900,\n",
      "          0.4200,   1.9700,   3.8400,   1.2300,   2.8700, 990.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.0500,   1.7700,   2.1000,  17.0000, 107.0000,   3.0000,   3.0000,\n",
      "          0.2800,   2.0300,   5.0400,   0.8800,   3.3500, 885.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 12.1700,   1.4500,   2.5300,  19.0000, 104.0000,   1.8900,   1.7500,\n",
      "          0.4500,   1.0300,   2.9500,   1.4500,   2.2300, 355.0000]), tensor(1))\n",
      "========\n",
      "(tensor([  13.0500,    1.6500,    2.5500,   18.0000,   98.0000,    2.4500,\n",
      "           2.4300,    0.2900,    1.4400,    4.2500,    1.1200,    2.5100,\n",
      "        1105.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 13.9000,   1.6800,   2.1200,  16.0000, 101.0000,   3.1000,   3.3900,\n",
      "          0.2100,   2.1400,   6.1000,   0.9100,   3.3300, 985.0000]), tensor(0))\n",
      "========\n",
      "(tensor([ 11.4500,   2.4000,   2.4200,  20.0000,  96.0000,   2.9000,   2.7900,\n",
      "          0.3200,   1.8300,   3.2500,   0.8000,   3.3900, 625.0000]), tensor(1))\n",
      "========\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000000000CB53080>\n"
     ]
    }
   ],
   "source": [
    "train = TensorDataset(train_X, train_Y) # torch.utils.data 내에 있는 함수로써 트레이닝 데이터 셋을 텐서화 시킨다\n",
    "\n",
    "\n",
    "for i in train: # train내부에는 데이터셋 / 라벨값 으로 구성돼있음\n",
    "    print(i)\n",
    "    print(\"========\")\n",
    "# print(train[2])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = 16, shuffle=True) \n",
    "# batch_size(epoch를 적정한 수로 나눈(iteration)중 회당 넣는 데이터셋 수)\n",
    "# torch.utils.data 내에 있는 함수로써 말그대로 데이터 로더의 역할을 한다\n",
    "# train\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__() # 상속받은 부모클래스의 init을 거친다\n",
    "        self.fc1 = nn.Linear(13,96) \n",
    "        # (x,y | y = Ax + b) 선형변환을 거친다 -> 인풋 13종류 => 아웃풋 96 종류 // 따라서 이 부분이 입력층---중간층이다\n",
    "        self.fc2 = nn.Linear(96,2)\n",
    "        # 추후 이 변수는 fc1의 리턴값을 받기때문에 fc1의 y값 개수가 x값 개수와 동일하다 최종적으로 2개의 출력값을 내놓는다 // 중간층 ---출력층\n",
    "    def forward(self, x): # 아직 이 함수가 어떻게 사용되어지는 모르겠지만 상속관계에서 호출되는 이유가 있는듯하다\n",
    "        x = F.relu(self.fc1(x)) # torch.nn.functional의 ReLu는 활성화함수로써 입력값에 비례한 값으로 변환을 해준다\n",
    "        x = self.fc2(x) # 위에서 얻은 값에 맞는 y값을 갖는다(fc2 직선 함수에서)\n",
    "        return F.log_softmax(x, dim = 1) # 위에서 얻은 x값을 소프트맥스 함수를 통해 총합이 1이 되도록 비율에 맞춰 값을 변환한다\n",
    "                                          # 정수배 개념이 아니다\n",
    "    \n",
    "    \n",
    "model = Net()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.8538, grad_fn=<NllLossBackward>)\n",
      "tensor(303940.8125, grad_fn=<NllLossBackward>)\n",
      "tensor(3.0669, grad_fn=<NllLossBackward>)\n",
      "tensor(79.7040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6916, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6904, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6891, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6821, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6801, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6787, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6866, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6765, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6983, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6760, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7316, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6969, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6973, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7081, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6972, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6869, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6778, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6561, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7594, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6752, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7164, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7526, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6979, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7439, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6953, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6868, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6965, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7168, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6791, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6959, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6971, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7208, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6569, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7213, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7188, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6691, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7042, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6379, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7716, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6657, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6622, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7592, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6655, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7077, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6687, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6751, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6341, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6587, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7305, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7145, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6732, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6498, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7176, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7292, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7285, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6293, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7250, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7006, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7277, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6740, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6472, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7160, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6454, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7138, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6221, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6701, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6573, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7552, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6761, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6529, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7226, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6586, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6981, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6538, grad_fn=<NllLossBackward>)\n",
      "50 4.815045475959778\n",
      "------------------\n",
      "tensor(0.7255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6500, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7101, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6460, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7299, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7334, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7633, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6998, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6997, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6583, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7283, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7103, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7079, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6673, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6990, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6738, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7102, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6501, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6738, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6989, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6658, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7184, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7260, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7085, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6748, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6979, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7254, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7237, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6757, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6732, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6636, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6557, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7112, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7207, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6519, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7098, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6522, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6990, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7301, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6990, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6971, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6543, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6991, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7553, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6537, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6596, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6529, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7285, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7127, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6749, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6620, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6357, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7331, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6990, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6598, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6696, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7568, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7158, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6719, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6671, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6974, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6560, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7110, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6983, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6974, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7000, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6575, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7135, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7233, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6967, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6964, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6954, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7121, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6744, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7136, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6747, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.6735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7255, grad_fn=<NllLossBackward>)\n",
      "------------------\n",
      "tensor(0.7082, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6615, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6748, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "100 4.831679880619049\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 손실함수를 지정한다 (분류문제에서는 crossentropy, 회귀문제에서는 mean_square_error를 사용)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1) # 최적화 도구로 sgd -> 확률적 경사하강법이다 lr = learn rate\n",
    "                                                    \n",
    "\n",
    "for epoch in range(100): # 100번의 시행\n",
    "    total_loss = 0\n",
    "     \n",
    "    for train_x, train_y in train_loader:\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # print(train_x) # 트레이닝 데이터셋이 총 104개 인데 배치사이즈가 16이므로\n",
    "                         # 배치 당 7개의 텐서를 갖는다\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(train_x)\n",
    "        \n",
    "        loss = criterion(output, train_y)\n",
    "        # print(train_x)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        # print(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    if (epoch+1)%50 == 0:\n",
    "        print(epoch+1, total_loss)\n",
    "   \n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_y: tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0])\n",
      "result : (tensor([-0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077,\n",
      "        -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077,\n",
      "        -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077, -0.6077,\n",
      "        -0.6077, -0.6077]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "print(\"test_y:\", test_y)\n",
    "print(\"result :\", torch.max(model(test_x).data, 1)) # 두번째 인수는 해당 차원에서 맥스값\n",
    "# 1보다 작은값 (소프트맥스의 리턴값) 을 log화 시키기 때문에 음수값으로 나온다\n",
    "                                                    \n",
    "# print(result)\n",
    "\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy())/len(test_y.data.numpy())\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2924e-37, 0.0000e+00, 1.7438e+02],\n",
      "        [4.1641e+12, 7.5338e+28, 5.0511e-39],\n",
      "        [1.8724e+28, 2.5353e+30, 1.3733e-43]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267780000000000000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.Tensor(3, 3)\n",
    "print(a)\n",
    "int(2.6778e+20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
